{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle #for reading the given files\n",
    "import numpy as np \n",
    "import cv2 #to read images\n",
    "import matplotlib.pyplot as plt #to show images and graphs\n",
    "\n",
    "#importing for our model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D, Flatten,MaxPooling2D,Dropout,Activation\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train_image.pkl', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open('test_image.pkl', 'rb') as f:\n",
    "    test = pickle.load(f)\n",
    "with open('train_label.pkl', 'rb') as f:\n",
    "    train_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Converting to numpy nd array\n",
    "train_np = np.array(train)\n",
    "test_np = np.array(test)\n",
    "train_labels_np = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 784), (2000, 784), (8000,))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_np.shape,test_np.shape,train_labels_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshaping the images in appropriate size (-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_img = train_np.reshape(-1,28,28,1)\n",
    "test_img = test_np.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 2, 3, 6}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(train_labels_np)\n",
    "set(train_labels_np)\n",
    "#converting these labels to (0,1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train_labels_np\n",
    "for i in range(len(y_train)):\n",
    "    if(y_train[i] == 0):\n",
    "        y_train[i] = 0\n",
    "    elif(y_train[i] == 2):\n",
    "        y_train[i] = 1\n",
    "    elif(y_train[i] == 3):\n",
    "        y_train[i] = 2\n",
    "    else:\n",
    "        y_train[i] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 4)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one-hot encoding the labels\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22118892b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking image\n",
    "plt.imshow(train_np[0].reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "## Library used to create model: Keras\n",
    "\n",
    "We are going to create a deep learning model. We are going to use **Convolutional Neural Network(CNN)** as they are highly effective on images and give excellent results on image classification\n",
    "\n",
    "## Our architecture: \n",
    "<ul><li> input image: 28x28x1 image</li></ul>\n",
    "<ol>\n",
    "<li>**Convolution layer**: filter: 3*3, units: 64, strides=1,padding: SAME (i.e image size remains same) </li>\n",
    "<ul><li> output of this layer: 28x28x64</li></ul><br/>\n",
    "<li>**Maxpool layer**: filter:2x2,strides=2</li>\n",
    "<ul><li> output of this layer: 14x14x64</li></ul><br/>\n",
    "<li>**Convolution layer**: filter: 3*3, units: 128, padding: SAME (i.e image size remains same)</li>\n",
    "<ul><li> output of this layer: 14x14x128</li></ul><br/>\n",
    "<li>**Maxpool layer**: filter:2x2,strides=2</li>\n",
    "<ul><li> output of this layer: 7x7x128</li></ul><br/>\n",
    "<li>**Dropout layer**: FOR REGULARIZATION(i.e prevent overfitting)</li>\n",
    "<li>**Flatten**: Now we flatten the array to pass it through the neural network</li>\n",
    "<ul><li> output of this layer: (1,6272)</li></ul><br/>\n",
    "<li>**Dense layer**: 1024 units, activation: relu</li>\n",
    "<li>**Output layer**: units: 4,activation: softmax</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(64,(3,3),padding='same',activation='relu',input_shape = (28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=None,padding='valid',data_format=None))\n",
    "model.add(Conv2D(128,(3,3),padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=None,padding='valid',data_format=None))\n",
    "model.add(Dropout(0.2, noise_shape=None, seed=None))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dense(4,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 47s 6ms/step - loss: 12.0717 - acc: 0.2505\n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 46s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 50s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 49s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - 48s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 6/50\n",
      "8000/8000 [==============================] - 48s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 7/50\n",
      "8000/8000 [==============================] - 49s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 8/50\n",
      "8000/8000 [==============================] - 50s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 9/50\n",
      "8000/8000 [==============================] - 48s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 10/50\n",
      "8000/8000 [==============================] - 49s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 11/50\n",
      "8000/8000 [==============================] - 49s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 12/50\n",
      "8000/8000 [==============================] - 49s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 13/50\n",
      "8000/8000 [==============================] - 49s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 14/50\n",
      "8000/8000 [==============================] - 50s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 15/50\n",
      "8000/8000 [==============================] - 48s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 16/50\n",
      "8000/8000 [==============================] - 46s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 17/50\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 18/50\n",
      "8000/8000 [==============================] - 47s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 19/50\n",
      "8000/8000 [==============================] - 49s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 20/50\n",
      "8000/8000 [==============================] - 49s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 21/50\n",
      "8000/8000 [==============================] - 49s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 22/50\n",
      "8000/8000 [==============================] - 49s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 23/50\n",
      "8000/8000 [==============================] - 49s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 24/50\n",
      "8000/8000 [==============================] - 49s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 25/50\n",
      "8000/8000 [==============================] - 49s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 26/50\n",
      "8000/8000 [==============================] - 49s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 27/50\n",
      "8000/8000 [==============================] - 47s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 28/50\n",
      "8000/8000 [==============================] - 47s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 29/50\n",
      "8000/8000 [==============================] - 46s 6ms/step - loss: 12.0886 - acc: 0.2500\n",
      "Epoch 30/50\n",
      "5120/8000 [==================>...........] - ETA: 16s - loss: 12.0728 - acc: 0.2510"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "model.fit(train_img, y_train, epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

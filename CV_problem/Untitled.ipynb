{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle #for reading the given files\n",
    "import numpy as np \n",
    "import cv2 #to read images\n",
    "import matplotlib.pyplot as plt #to show images and graphs\n",
    "\n",
    "#importing for our model\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D, Flatten,MaxPooling2D,Dropout,Activation\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train_image.pkl', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open('test_image.pkl', 'rb') as f:\n",
    "    test = pickle.load(f)\n",
    "with open('train_label.pkl', 'rb') as f:\n",
    "    train_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Converting to numpy nd array\n",
    "train_np = np.array(train)\n",
    "test_np = np.array(test)\n",
    "train_labels_np = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 784), (2000, 784), (8000,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_np.shape,test_np.shape,train_labels_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshaping the images in appropriate size (-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = train_np.reshape(-1,28,28,1)\n",
    "test_img = test_np.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_img.astype('float32')\n",
    "X_test = test_img.astype('float32')\n",
    "#X_val = X_val.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "#X_val /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 2, 3, 6}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(train_labels_np)\n",
    "set(train_labels_np)\n",
    "#converting these labels to (0,1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train_labels_np\n",
    "for i in range(len(y_train)):\n",
    "    if(y_train[i] == 0):\n",
    "        y_train[i] = 0\n",
    "    elif(y_train[i] == 2):\n",
    "        y_train[i] = 1\n",
    "    elif(y_train[i] == 3):\n",
    "        y_train[i] = 2\n",
    "    else:\n",
    "        y_train[i] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 0, 0, 1, 3, 0, 3, 1, 3, 0, 1, 3, 3, 2, 3, 0, 2, 3, 3, 1,\n",
       "       3, 0, 2, 3, 2, 1, 3, 0, 2, 3, 0, 2, 0, 1, 1, 2, 3, 1, 0, 2, 1, 0, 0,\n",
       "       3, 0, 0, 3, 3, 2, 0, 2, 2, 1, 1, 2, 3, 1, 0, 1, 0, 2, 3, 2, 3, 0, 2,\n",
       "       1, 3, 3, 1, 2, 3, 0, 1, 1, 1, 1, 0, 3, 3, 3, 0, 2, 1, 2, 0, 3, 3, 2,\n",
       "       1, 3, 0, 3, 2, 1, 1, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 4)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one-hot encoding the labels\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6800, 28, 28, 1), (1200, 28, 28, 1), (6800, 4), (1200, 4))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_val,Y_train,Y_val = train_test_split(X_train,y_train,test_size=0.15)\n",
    "X_train.shape,X_val.shape,Y_train.shape,Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20c7fa90e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking image\n",
    "plt.imshow(train_np[0].reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "## Library used to create model: Keras\n",
    "\n",
    "We are going to create a deep learning model. We are going to use **Convolutional Neural Network(CNN)** as they are highly effective on images and give excellent results on image classification\n",
    "\n",
    "## Our architecture: \n",
    "<ul><li> input image: 28x28x1 image</li></ul>\n",
    "<ol>\n",
    "<li>**Convolution layer**: filter: 3*3, units: 64, strides=1,padding: SAME (i.e image size remains same) </li>\n",
    "<ul><li> output of this layer: 28x28x64</li></ul><br/>\n",
    "<li>**Maxpool layer**: filter:2x2,strides=2</li>\n",
    "<ul><li> output of this layer: 14x14x64</li></ul><br/>\n",
    "<li>**Convolution layer**: filter: 3*3, units: 128, padding: SAME (i.e image size remains same)</li>\n",
    "<ul><li> output of this layer: 14x14x128</li></ul><br/>\n",
    "<li>**Maxpool layer**: filter:2x2,strides=2</li>\n",
    "<ul><li> output of this layer: 7x7x128</li></ul><br/>\n",
    "<li>**Dropout layer**: FOR REGULARIZATION(i.e prevent overfitting)</li>\n",
    "<li>**Flatten**: Now we flatten the array to pass it through the neural network</li>\n",
    "<ul><li> output of this layer: (1,6272)</li></ul><br/>\n",
    "<li>**Dense layer**: 1024 units, activation: relu</li>\n",
    "<li>**Output layer**: units: 4,activation: softmax</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating a model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(64,(3,3),padding='same',activation='relu',input_shape = (28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=None,padding='valid',data_format=None))\n",
    "model.add(Conv2D(128,(3,3),padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=None,padding='valid',data_format=None))\n",
    "model.add(Dropout(0.2, noise_shape=None, seed=None))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dense(4,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6800 samples, validate on 1200 samples\n",
      "Epoch 1/50\n",
      "6800/6800 [==============================] - 35s 5ms/step - loss: 1.3906 - acc: 0.2403 - val_loss: 1.3863 - val_acc: 0.2442\n",
      "Epoch 2/50\n",
      "6800/6800 [==============================] - 34s 5ms/step - loss: 1.3866 - acc: 0.2353 - val_loss: 1.3866 - val_acc: 0.2392\n",
      "Epoch 3/50\n",
      "6800/6800 [==============================] - 34s 5ms/step - loss: 1.3865 - acc: 0.2456 - val_loss: 1.3865 - val_acc: 0.2400\n",
      "Epoch 4/50\n",
      "6800/6800 [==============================] - 34s 5ms/step - loss: 1.3865 - acc: 0.2478 - val_loss: 1.3867 - val_acc: 0.2433\n",
      "Epoch 5/50\n",
      "6800/6800 [==============================] - 34s 5ms/step - loss: 1.3866 - acc: 0.2366 - val_loss: 1.3866 - val_acc: 0.2350\n",
      "Epoch 6/50\n",
      "6800/6800 [==============================] - 35s 5ms/step - loss: 1.3866 - acc: 0.2553 - val_loss: 1.3863 - val_acc: 0.2508\n",
      "Epoch 7/50\n",
      "6800/6800 [==============================] - 35s 5ms/step - loss: 1.3867 - acc: 0.2454 - val_loss: 1.3859 - val_acc: 0.2583\n",
      "Epoch 8/50\n",
      "6800/6800 [==============================] - 35s 5ms/step - loss: 1.3870 - acc: 0.2553 - val_loss: 1.3866 - val_acc: 0.2550\n",
      "Epoch 9/50\n",
      "6800/6800 [==============================] - 34s 5ms/step - loss: 1.3863 - acc: 0.2581 - val_loss: 1.3878 - val_acc: 0.2458\n",
      "Epoch 10/50\n",
      "6800/6800 [==============================] - 35s 5ms/step - loss: 1.3855 - acc: 0.2668 - val_loss: 1.3885 - val_acc: 0.2342\n",
      "Epoch 11/50\n",
      "6800/6800 [==============================] - 38s 6ms/step - loss: 1.3843 - acc: 0.2712 - val_loss: 1.3892 - val_acc: 0.2250\n",
      "Epoch 12/50\n",
      "6800/6800 [==============================] - 35s 5ms/step - loss: 1.3823 - acc: 0.2646 - val_loss: 1.3891 - val_acc: 0.2592\n",
      "Epoch 13/50\n",
      "6800/6800 [==============================] - 35s 5ms/step - loss: 1.3775 - acc: 0.2857 - val_loss: 1.4068 - val_acc: 0.2617\n",
      "Epoch 14/50\n",
      "6800/6800 [==============================] - 35s 5ms/step - loss: 1.3718 - acc: 0.2907 - val_loss: 1.3953 - val_acc: 0.2400\n",
      "Epoch 15/50\n",
      "6800/6800 [==============================] - 37s 5ms/step - loss: 1.3629 - acc: 0.3057 - val_loss: 1.4087 - val_acc: 0.2350\n",
      "Epoch 16/50\n",
      "6800/6800 [==============================] - 35s 5ms/step - loss: 1.3470 - acc: 0.3154 - val_loss: 1.4153 - val_acc: 0.2458\n",
      "Epoch 17/50\n",
      "6800/6800 [==============================] - 36s 5ms/step - loss: 1.3232 - acc: 0.3476 - val_loss: 1.4241 - val_acc: 0.2533\n",
      "Epoch 18/50\n",
      "6800/6800 [==============================] - 37s 5ms/step - loss: 1.2813 - acc: 0.3900 - val_loss: 1.4450 - val_acc: 0.2492\n",
      "Epoch 19/50\n",
      "6800/6800 [==============================] - 39s 6ms/step - loss: 1.2276 - acc: 0.4324 - val_loss: 1.4801 - val_acc: 0.2550\n",
      "Epoch 20/50\n",
      "6800/6800 [==============================] - 35s 5ms/step - loss: 1.1581 - acc: 0.4724 - val_loss: 1.5429 - val_acc: 0.2650\n",
      "Epoch 21/50\n",
      "6800/6800 [==============================] - 35s 5ms/step - loss: 1.0824 - acc: 0.5153 - val_loss: 1.5837 - val_acc: 0.2542\n",
      "Epoch 22/50\n",
      "6800/6800 [==============================] - 35s 5ms/step - loss: 1.0068 - acc: 0.5662 - val_loss: 1.6753 - val_acc: 0.2525\n",
      "Epoch 23/50\n",
      "6800/6800 [==============================] - 35s 5ms/step - loss: 0.9121 - acc: 0.6172 - val_loss: 1.7547 - val_acc: 0.2525\n",
      "Epoch 24/50\n",
      "6800/6800 [==============================] - 37s 5ms/step - loss: 0.8202 - acc: 0.6612 - val_loss: 1.8318 - val_acc: 0.2367\n",
      "Epoch 25/50\n",
      "6800/6800 [==============================] - 36s 5ms/step - loss: 0.7407 - acc: 0.6984 - val_loss: 1.9582 - val_acc: 0.2542\n",
      "Epoch 26/50\n",
      "6800/6800 [==============================] - 37s 5ms/step - loss: 0.6722 - acc: 0.7316 - val_loss: 1.9942 - val_acc: 0.2542\n",
      "Epoch 27/50\n",
      "6800/6800 [==============================] - 35s 5ms/step - loss: 0.5907 - acc: 0.7706 - val_loss: 2.1734 - val_acc: 0.2550\n",
      "Epoch 28/50\n",
      "6800/6800 [==============================] - 37s 5ms/step - loss: 0.5257 - acc: 0.8015 - val_loss: 2.3210 - val_acc: 0.2658\n",
      "Epoch 29/50\n",
      "6800/6800 [==============================] - 36s 5ms/step - loss: 0.4732 - acc: 0.8278 - val_loss: 2.4254 - val_acc: 0.2533\n",
      "Epoch 30/50\n",
      "6800/6800 [==============================] - 36s 5ms/step - loss: 0.4178 - acc: 0.8469 - val_loss: 2.4866 - val_acc: 0.2558\n",
      "Epoch 31/50\n",
      "6800/6800 [==============================] - 37s 5ms/step - loss: 0.3657 - acc: 0.8681 - val_loss: 2.6663 - val_acc: 0.2617\n",
      "Epoch 32/50\n",
      "6800/6800 [==============================] - 42s 6ms/step - loss: 0.3366 - acc: 0.8775 - val_loss: 2.6892 - val_acc: 0.2600\n",
      "Epoch 33/50\n",
      "6800/6800 [==============================] - 37s 5ms/step - loss: 0.2900 - acc: 0.8979 - val_loss: 2.8536 - val_acc: 0.2475\n",
      "Epoch 34/50\n",
      "6800/6800 [==============================] - 37s 5ms/step - loss: 0.2562 - acc: 0.9100 - val_loss: 2.9946 - val_acc: 0.2483\n",
      "Epoch 35/50\n",
      "6800/6800 [==============================] - 36s 5ms/step - loss: 0.2477 - acc: 0.9168 - val_loss: 3.0884 - val_acc: 0.2608\n",
      "Epoch 36/50\n",
      "6800/6800 [==============================] - 35s 5ms/step - loss: 0.2176 - acc: 0.9290 - val_loss: 3.1681 - val_acc: 0.2592\n",
      "Epoch 37/50\n",
      "6800/6800 [==============================] - 37s 5ms/step - loss: 0.1832 - acc: 0.9390 - val_loss: 3.2139 - val_acc: 0.2583\n",
      "Epoch 38/50\n",
      "6800/6800 [==============================] - 40s 6ms/step - loss: 0.1721 - acc: 0.9447 - val_loss: 3.2986 - val_acc: 0.2533\n",
      "Epoch 39/50\n",
      "6800/6800 [==============================] - 39s 6ms/step - loss: 0.1701 - acc: 0.9438 - val_loss: 3.3869 - val_acc: 0.2558\n",
      "Epoch 40/50\n",
      "6800/6800 [==============================] - 36s 5ms/step - loss: 0.1525 - acc: 0.9512 - val_loss: 3.6425 - val_acc: 0.2467\n",
      "Epoch 41/50\n",
      "6800/6800 [==============================] - 36s 5ms/step - loss: 0.1560 - acc: 0.9500 - val_loss: 3.4989 - val_acc: 0.2533\n",
      "Epoch 42/50\n",
      "6800/6800 [==============================] - 39s 6ms/step - loss: 0.1268 - acc: 0.9612 - val_loss: 3.4595 - val_acc: 0.2625\n",
      "Epoch 43/50\n",
      "6800/6800 [==============================] - 40s 6ms/step - loss: 0.1282 - acc: 0.9582 - val_loss: 3.6239 - val_acc: 0.2525\n",
      "Epoch 44/50\n",
      "6800/6800 [==============================] - 38s 6ms/step - loss: 0.1089 - acc: 0.9649 - val_loss: 3.6436 - val_acc: 0.2617\n",
      "Epoch 45/50\n",
      "6800/6800 [==============================] - 37s 5ms/step - loss: 0.1010 - acc: 0.9678 - val_loss: 3.6893 - val_acc: 0.2683\n",
      "Epoch 46/50\n",
      "6800/6800 [==============================] - 37s 5ms/step - loss: 0.0826 - acc: 0.9743 - val_loss: 3.9218 - val_acc: 0.2558\n",
      "Epoch 47/50\n",
      "6800/6800 [==============================] - 38s 6ms/step - loss: 0.0867 - acc: 0.9725 - val_loss: 3.8925 - val_acc: 0.2742\n",
      "Epoch 48/50\n",
      "6800/6800 [==============================] - 37s 5ms/step - loss: 0.0931 - acc: 0.9691 - val_loss: 3.8903 - val_acc: 0.2675\n",
      "Epoch 49/50\n",
      "6800/6800 [==============================] - 37s 5ms/step - loss: 0.0909 - acc: 0.9682 - val_loss: 3.8732 - val_acc: 0.2617\n",
      "Epoch 50/50\n",
      "6800/6800 [==============================] - 38s 6ms/step - loss: 0.0696 - acc: 0.9781 - val_loss: 4.1099 - val_acc: 0.2608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20c03cf42e8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "model.fit(X_train, Y_train,validation_data=(X_val,Y_val), epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal',input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 240,772\n",
      "Trainable params: 240,772\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6800 samples, validate on 1200 samples\n",
      "Epoch 1/50\n",
      "6800/6800 [==============================] - 6s 922us/step - loss: 1.2445 - acc: 0.3881 - val_loss: 1.5055 - val_acc: 0.2475\n",
      "Epoch 2/50\n",
      "6800/6800 [==============================] - 6s 945us/step - loss: 1.2351 - acc: 0.3932 - val_loss: 1.5016 - val_acc: 0.2283\n",
      "Epoch 3/50\n",
      "6800/6800 [==============================] - 6s 933us/step - loss: 1.2379 - acc: 0.3959 - val_loss: 1.5164 - val_acc: 0.2367\n",
      "Epoch 4/50\n",
      "6800/6800 [==============================] - 6s 950us/step - loss: 1.2287 - acc: 0.3981 - val_loss: 1.5095 - val_acc: 0.2350\n",
      "Epoch 5/50\n",
      "6800/6800 [==============================] - 6s 953us/step - loss: 1.2377 - acc: 0.3971 - val_loss: 1.5168 - val_acc: 0.2242\n",
      "Epoch 6/50\n",
      "6800/6800 [==============================] - 6s 944us/step - loss: 1.2317 - acc: 0.3925 - val_loss: 1.5013 - val_acc: 0.2275\n",
      "Epoch 7/50\n",
      "6800/6800 [==============================] - 6s 951us/step - loss: 1.2285 - acc: 0.3935 - val_loss: 1.5214 - val_acc: 0.2375\n",
      "Epoch 8/50\n",
      "6800/6800 [==============================] - 6s 950us/step - loss: 1.2181 - acc: 0.4046 - val_loss: 1.5432 - val_acc: 0.2383\n",
      "Epoch 9/50\n",
      "6800/6800 [==============================] - 7s 988us/step - loss: 1.2235 - acc: 0.4079 - val_loss: 1.5331 - val_acc: 0.2358\n",
      "Epoch 10/50\n",
      "6800/6800 [==============================] - 7s 966us/step - loss: 1.2118 - acc: 0.4119 - val_loss: 1.5412 - val_acc: 0.2433\n",
      "Epoch 11/50\n",
      "6800/6800 [==============================] - 7s 966us/step - loss: 1.2145 - acc: 0.4118 - val_loss: 1.5463 - val_acc: 0.2392\n",
      "Epoch 12/50\n",
      "6800/6800 [==============================] - 7s 963us/step - loss: 1.2119 - acc: 0.4196 - val_loss: 1.5491 - val_acc: 0.2433\n",
      "Epoch 13/50\n",
      "6800/6800 [==============================] - 7s 985us/step - loss: 1.2095 - acc: 0.4137 - val_loss: 1.5381 - val_acc: 0.2467\n",
      "Epoch 14/50\n",
      "6800/6800 [==============================] - 8s 1ms/step - loss: 1.2120 - acc: 0.4118 - val_loss: 1.5240 - val_acc: 0.2433\n",
      "Epoch 15/50\n",
      "6800/6800 [==============================] - 7s 1ms/step - loss: 1.1999 - acc: 0.4249 - val_loss: 1.5475 - val_acc: 0.2442\n",
      "Epoch 16/50\n",
      "6800/6800 [==============================] - 7s 1ms/step - loss: 1.2022 - acc: 0.4176 - val_loss: 1.5491 - val_acc: 0.2342\n",
      "Epoch 17/50\n",
      "6800/6800 [==============================] - 7s 961us/step - loss: 1.1997 - acc: 0.4124 - val_loss: 1.5502 - val_acc: 0.2375\n",
      "Epoch 18/50\n",
      "6800/6800 [==============================] - 7s 959us/step - loss: 1.1942 - acc: 0.4163 - val_loss: 1.5610 - val_acc: 0.2400\n",
      "Epoch 19/50\n",
      "6800/6800 [==============================] - 7s 959us/step - loss: 1.1964 - acc: 0.4241 - val_loss: 1.5494 - val_acc: 0.2433\n",
      "Epoch 20/50\n",
      "6800/6800 [==============================] - 7s 1ms/step - loss: 1.1936 - acc: 0.4253 - val_loss: 1.5534 - val_acc: 0.2308\n",
      "Epoch 21/50\n",
      "6800/6800 [==============================] - 7s 1ms/step - loss: 1.1920 - acc: 0.4266 - val_loss: 1.5409 - val_acc: 0.2375\n",
      "Epoch 22/50\n",
      "6800/6800 [==============================] - 7s 987us/step - loss: 1.1751 - acc: 0.4306 - val_loss: 1.5536 - val_acc: 0.2267\n",
      "Epoch 23/50\n",
      "6800/6800 [==============================] - 8s 1ms/step - loss: 1.1742 - acc: 0.4376 - val_loss: 1.5499 - val_acc: 0.2425\n",
      "Epoch 24/50\n",
      "6800/6800 [==============================] - 9s 1ms/step - loss: 1.1800 - acc: 0.4253 - val_loss: 1.5503 - val_acc: 0.2517\n",
      "Epoch 25/50\n",
      "6800/6800 [==============================] - 7s 1ms/step - loss: 1.1782 - acc: 0.4368 - val_loss: 1.5522 - val_acc: 0.2517\n",
      "Epoch 26/50\n",
      "6800/6800 [==============================] - 7s 997us/step - loss: 1.1749 - acc: 0.4388 - val_loss: 1.5585 - val_acc: 0.2325\n",
      "Epoch 27/50\n",
      "6800/6800 [==============================] - 7s 995us/step - loss: 1.1640 - acc: 0.4412 - val_loss: 1.5794 - val_acc: 0.2292\n",
      "Epoch 28/50\n",
      "6800/6800 [==============================] - 7s 1ms/step - loss: 1.1686 - acc: 0.4435 - val_loss: 1.5603 - val_acc: 0.2408\n",
      "Epoch 29/50\n",
      "6800/6800 [==============================] - 7s 1ms/step - loss: 1.1646 - acc: 0.4363 - val_loss: 1.5564 - val_acc: 0.2450\n",
      "Epoch 30/50\n",
      "6800/6800 [==============================] - 7s 1ms/step - loss: 1.1621 - acc: 0.4429 - val_loss: 1.5564 - val_acc: 0.2433\n",
      "Epoch 31/50\n",
      "6800/6800 [==============================] - 7s 976us/step - loss: 1.1561 - acc: 0.4422 - val_loss: 1.5760 - val_acc: 0.2458\n",
      "Epoch 32/50\n",
      "6800/6800 [==============================] - 7s 1ms/step - loss: 1.1588 - acc: 0.4422 - val_loss: 1.5665 - val_acc: 0.2442\n",
      "Epoch 33/50\n",
      "6800/6800 [==============================] - 7s 1ms/step - loss: 1.1478 - acc: 0.4529 - val_loss: 1.5887 - val_acc: 0.2450\n",
      "Epoch 34/50\n",
      "6800/6800 [==============================] - 7s 1ms/step - loss: 1.1531 - acc: 0.4551 - val_loss: 1.5735 - val_acc: 0.2450\n",
      "Epoch 35/50\n",
      "6800/6800 [==============================] - 8s 1ms/step - loss: 1.1477 - acc: 0.4509 - val_loss: 1.5948 - val_acc: 0.2475\n",
      "Epoch 36/50\n",
      "6800/6800 [==============================] - 7s 1ms/step - loss: 1.1506 - acc: 0.4560 - val_loss: 1.5911 - val_acc: 0.2350\n",
      "Epoch 37/50\n",
      "6800/6800 [==============================] - 7s 1ms/step - loss: 1.1388 - acc: 0.4600 - val_loss: 1.5868 - val_acc: 0.2467\n",
      "Epoch 38/50\n",
      "6800/6800 [==============================] - 7s 1ms/step - loss: 1.1300 - acc: 0.4569 - val_loss: 1.6095 - val_acc: 0.2442\n",
      "Epoch 39/50\n",
      "6800/6800 [==============================] - 7s 1ms/step - loss: 1.1450 - acc: 0.4610 - val_loss: 1.6007 - val_acc: 0.2458\n",
      "Epoch 40/50\n",
      "6800/6800 [==============================] - 7s 1ms/step - loss: 1.1375 - acc: 0.4591 - val_loss: 1.5867 - val_acc: 0.2550\n",
      "Epoch 41/50\n",
      "6800/6800 [==============================] - 7s 1ms/step - loss: 1.1442 - acc: 0.4566 - val_loss: 1.6034 - val_acc: 0.2483\n",
      "Epoch 42/50\n",
      "6800/6800 [==============================] - 7s 1ms/step - loss: 1.1366 - acc: 0.4634 - val_loss: 1.5880 - val_acc: 0.2333\n",
      "Epoch 43/50\n",
      "6800/6800 [==============================] - 7s 1ms/step - loss: 1.1228 - acc: 0.4634 - val_loss: 1.6003 - val_acc: 0.2325\n",
      "Epoch 44/50\n",
      "6800/6800 [==============================] - 7s 1ms/step - loss: 1.1345 - acc: 0.4696 - val_loss: 1.5957 - val_acc: 0.2367\n",
      "Epoch 45/50\n",
      "6800/6800 [==============================] - 7s 1ms/step - loss: 1.1261 - acc: 0.4657 - val_loss: 1.6025 - val_acc: 0.2383\n",
      "Epoch 46/50\n",
      "6800/6800 [==============================] - 7s 1ms/step - loss: 1.1230 - acc: 0.4731 - val_loss: 1.6194 - val_acc: 0.2467\n",
      "Epoch 47/50\n",
      "6800/6800 [==============================] - 7s 1ms/step - loss: 1.1194 - acc: 0.4701 - val_loss: 1.6076 - val_acc: 0.2433\n",
      "Epoch 48/50\n",
      "6800/6800 [==============================] - 7s 989us/step - loss: 1.1183 - acc: 0.4694 - val_loss: 1.6213 - val_acc: 0.2533\n",
      "Epoch 49/50\n",
      "6800/6800 [==============================] - 7s 985us/step - loss: 1.1163 - acc: 0.4781 - val_loss: 1.6333 - val_acc: 0.2425\n",
      "Epoch 50/50\n",
      "6800/6800 [==============================] - 7s 985us/step - loss: 1.1150 - acc: 0.4762 - val_loss: 1.6289 - val_acc: 0.2417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20c0fe76128>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train,validation_data=(X_val,Y_val), epochs=50,batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
